data:
  dataset_name_or_path: data/images.json
  spatial_size: 256

model:
  down_block_types:
    - SpatialDownBlock2D
    - SpatialDownBlock2D
    - SpatialDownBlock2D
    - SpatialDownBlock2D
  up_block_types:
    - SpatialUpBlock2D
    - SpatialUpBlock2D
    - SpatialUpBlock2D
    - SpatialUpBlock2D
  block_out_channels:
    - 128
    - 256
    - 512
    - 512
  mid_block_type: MidBlock2D
  mid_block_use_attention: True
  mid_block_attention_type: spatial
  layers_per_block: 2
  latent_channels: 4
  image_mode: True
  reconstruction_loss_type: l1
  reconstruction_loss_weight: 1.0
  perceptual_loss_weight: 1.0
  kl_loss_weight: 0.00001
  discriminator_loss_weight: 0.5
  disc_block_out_channels:
    - 128
    - 256
    - 512
    - 512
    - 512
  load_from_2d_vae: weights/vae-ft-mse-840000-ema-pruned.ckpt

optimizer:
  learning_rate: 0.0002
  lr_scheduler: WarmupCosineLR
  lr_warmup_steps: 500

runner:
  runner_cls_path: omni_gen.runners.vae_ds_trainer.VAEDeepSpeedTrainer
  name: VideoVAE
  num_devices: 8
  max_steps: 100_000
  train_batch_size: 16
  val_batch_size: 16
  seed: 23333
  use_ema: True
  ema_power: 0.75
  gradient_accumulation_steps: 1
  zero_stage: 2
  gradient_checkpointing: False
  # mixed_precision: bf16
  validation_every_n_steps: 10
  checkpointing_every_n_steps: 10
  discriminator_start_steps: 0
  # log_with: wandb
  log_every_n_steps: 5
