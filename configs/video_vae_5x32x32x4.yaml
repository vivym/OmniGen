data:
  dataset_name_or_path: data/videos.json
  spatial_size: 256
  num_frames: 17
  frame_intervals:
    - 1
    - 2
    - 4
    - 8

model:
  down_block_types:
    - SpatialDownBlock3D
    - SpatialTemporalDownBlock3D
    - SpatialTemporalDownBlock3D
    - SpatialTemporalDownBlock3D
  up_block_types:
    - SpatialTemporalUpBlock3D
    - SpatialTemporalUpBlock3D
    - SpatialUpBlock3D
    - SpatialUpBlock3D
  block_out_channels:
    - 128
    - 256
    - 512
    - 512
  mid_block_use_attention: True
  mid_block_attention_type: spatial
  layers_per_block: 2
  latent_channels: 4
  reconstruction_loss_type: l1
  reconstruction_loss_weight: 1.0
  perceptual_loss_weight: 1.0
  kl_loss_weight: 0.00001
  discriminator_loss_weight: 0.5
  disc_block_out_channels:
    - 128
    - 256
    - 512
    - 512
  load_from_2d_vae: weights/vae-ft-mse-840000-ema-pruned.ckpt

optimizer:
  learning_rate: 0.0002
  lr_scheduler: WarmupCosineLR
  lr_warmup_steps: 500

runner:
  runner_cls_path: omni_gen.runners.vae_ds_trainer.VAEDeepSpeedTrainer
  name: VideoVAE
  num_devices: 8
  max_steps: 100_000
  train_batch_size: 2
  val_batch_size: 2
  seed: 23333
  use_ema: True
  ema_power: 0.75
  gradient_accumulation_steps: 8
  zero_stage: 2
  gradient_checkpointing: False
  mixed_precision: bf16
  validation_every_n_steps: 250
  checkpointing_every_n_steps: 500
  discriminator_start_steps: 1000
  log_with: wandb
  log_every_n_steps: 5
